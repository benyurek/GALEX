This bash script implements a recursive job submission system for the SLURM workload manager that automatically chains together multiple processing jobs in sequence. The script requests minimal resources with only 10 CPU cores and a 1-minute time limit on the windfall partition, as it's designed purely for job orchestration rather than computational work. When executed, the script takes a single integer argument that serves as an iteration counter, increments this value by one, and then checks whether the current iteration number is less than or equal to a predefined limit. If the limit has not been reached, the script submits two new SLURM jobs: first it submits separgparse2.slurm with the current iteration number to perform the actual data processing work for that batch, and then it recursively submits itself (recurseSepargparse2.slurm) with the incremented iteration number to continue the chain. This recursive submission pattern allows the pipeline to automatically process a sequence of batches without manual intervention, with each recurseSepargparse2 job spawning the next processing job and the next recursive controller in the sequence until all batches have been queued. Once the iteration counter exceeds the specified limit, the recursion terminates and no additional jobs are submitted, with the script printing a message indicating the limit has been reached. This design is particularly useful for processing large numbers of sky coordinate batches where the total number of jobs would exceed SLURM's array job limits or where sequential rather than fully parallel processing is preferred to manage cluster resource usage, effectively creating a self-perpetuating job chain that processes the entire dataset batch by batch.
